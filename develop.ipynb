{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cac86266-10b8-4d9b-ad35-f3c04e258249",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vetak/projects/envs/env_3.12.3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "SentenceTransformer.__init__() got an unexpected keyword argument 'request_timeout'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[101]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m os.environ[\u001b[33m'\u001b[39m\u001b[33mHF_TRANSFER_TIMEOUT\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m'\u001b[39m\u001b[33m100\u001b[39m\u001b[33m'\u001b[39m  \u001b[38;5;66;03m# Увеличиваем таймаут для HF\u001b[39;00m\n\u001b[32m      6\u001b[39m os.environ[\u001b[33m'\u001b[39m\u001b[33mHF_HUB_DOWNLOAD_TIMEOUT\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m'\u001b[39m\u001b[33m600\u001b[39m\u001b[33m'\u001b[39m  \u001b[38;5;66;03m# Увеличиваем таймаут загрузки\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m embedding_model = \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msentence-transformers/paraphrase-multilingual-mpnet-base-v2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Дополнительные опции для requests\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m120\u001b[39;49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m test_embedding = embedding_model.embed_query(\u001b[33m\"\u001b[39m\u001b[33mFastAPI is a modern web frameworffk\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mРазмерность эмбеддинга: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_embedding)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: SentenceTransformer.__init__() got an unexpected keyword argument 'request_timeout'"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "\n",
    "# Попробуйте увеличить таймаут (в секундах)\n",
    "os.environ['HF_TRANSFER_TIMEOUT'] = '100'  # Увеличиваем таймаут для HF\n",
    "os.environ['HF_HUB_DOWNLOAD_TIMEOUT'] = '600'  # Увеличиваем таймаут загрузки\n",
    "\n",
    "embedding_model = SentenceTransformer(\n",
    "    model_name_or_path='sentence-transformers/paraphrase-multilingual-mpnet-base-v2',\n",
    "    # Дополнительные опции для requests\n",
    "    request_timeout=120\n",
    ")\n",
    "test_embedding = embedding_model.embed_query(\"FastAPI is a modern web frameworffk\")\n",
    "print(f\"Размерность эмбеддинга: {len(test_embedding)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efe3746b-434b-4243-b860-c2ef6015ff9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SentenceTransformer.__init__() got an unexpected keyword argument 'model_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_huggingface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mintfloat/multilingual-e5-large\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Инициализация модели для создания эмбеддингов\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Хорошая модель для старта: all-MiniLM-L6-v2\u001b[39;00m\n\u001b[32m      5\u001b[39m embedding_model = HuggingFaceEmbeddings(\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\u001b[39;00m\n\u001b[32m      7\u001b[39m     model_name = \u001b[33m'\u001b[39m\u001b[33mintfloat/multilingual-e5-large\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      8\u001b[39m     model_kwargs={\u001b[33m'\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m}, \n\u001b[32m      9\u001b[39m     encode_kwargs={\u001b[33m'\u001b[39m\u001b[33mnormalize_embeddings\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}  \u001b[38;5;66;03m# Нормализация для косинусного сходства\u001b[39;00m\n\u001b[32m     10\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: SentenceTransformer.__init__() got an unexpected keyword argument 'model_name'"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "# Инициализация модели для создания эмбеддингов\n",
    "# Хорошая модель для старта: all-MiniLM-L6-v2\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    # model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_name = 'intfloat/multilingual-e5-large',\n",
    "    model_kwargs={'device': 'cpu'}, \n",
    "    encode_kwargs={'normalize_embeddings': True}  # Нормализация для косинусного сходства\n",
    ")\n",
    "\n",
    "# Тестируем модель\n",
    "test_embedding = embedding_model.embed_query(\"FastAPI is a modern web frameworffk\")\n",
    "print(f\"Размерность эмбеддинга: {len(test_embedding)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ab9b91a-3f3d-45ce-8d97-6e45546be727",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(url='localhost:6333')  # Используйте \"localhost:6333\" для standalone-сервера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36617a65-3813-4a90-8909-4ffb1633dfe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "974daad2-92fb-4ed1-ab53-a0de793ba15e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mКоллекция可能 уже существует: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Инициализация векторного хранилища LangChain для Qdrant\u001b[39;00m\n\u001b[32m     27\u001b[39m vector_store = Qdrant(\n\u001b[32m     28\u001b[39m     client=client,\n\u001b[32m     29\u001b[39m     collection_name=\u001b[33m\"\u001b[39m\u001b[33mfastapi_docs\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     embeddings=\u001b[43membedding_model\u001b[49m,\n\u001b[32m     31\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'embedding_model' is not defined"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "from langchain.vectorstores import Qdrant\n",
    "\n",
    "# Локальный режим (для тестирования)\n",
    "client = QdrantClient(\":memory:\")  # Используйте \"localhost:6333\" для standalone-сервера\n",
    "\n",
    "# Или подключение к Qdrant Cloud\n",
    "# client = QdrantClient(\n",
    "#     url=\"your-cluster-url\",\n",
    "#     api_key=\"your-api-key\",\n",
    "# )\n",
    "\n",
    "# Создание коллекции (если её нет)\n",
    "try:\n",
    "    client.create_collection(\n",
    "        collection_name=\"fastapi_docs\",\n",
    "        vectors_config=VectorParams(\n",
    "            size=384,  # Должно соответствовать размерности выбранной модели эмбеддингов!\n",
    "            distance=Distance.COSINE  # Косинусное расстояние для семантического сходства\n",
    "        )\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Коллекция可能 уже существует: {e}\")\n",
    "\n",
    "# Инициализация векторного хранилища LangChain для Qdrant\n",
    "vector_store = Qdrant(\n",
    "    client=client,\n",
    "    collection_name=\"fastapi_docs\",\n",
    "    embeddings=embedding_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "340cc9ce-94a0-49b9-b57e-ead553be3606",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mКоллекция可能 уже существует: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Инициализация векторного хранилища LangChain для Qdrant\u001b[39;00m\n\u001b[32m     27\u001b[39m vector_store = Qdrant(\n\u001b[32m     28\u001b[39m     client=client,\n\u001b[32m     29\u001b[39m     collection_name=\u001b[33m\"\u001b[39m\u001b[33mfastapi_docs\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     embeddings=\u001b[43membedding_model\u001b[49m,\n\u001b[32m     31\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'embedding_model' is not defined"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "from langchain.vectorstores import Qdrant\n",
    "\n",
    "# Локальный режим (для тестирования)\n",
    "client = QdrantClient(\":memory:\")  # Используйте \"localhost:6333\" для standalone-сервера\n",
    "\n",
    "# Или подключение к Qdrant Cloud\n",
    "# client = QdrantClient(\n",
    "#     url=\"your-cluster-url\",\n",
    "#     api_key=\"your-api-key\",\n",
    "# )\n",
    "\n",
    "# Создание коллекции (если её нет)\n",
    "try:\n",
    "    client.create_collection(\n",
    "        collection_name=\"fastapi_docs\",\n",
    "        vectors_config=VectorParams(\n",
    "            size=384,  # Должно соответствовать размерности выбранной модели эмбеддингов!\n",
    "            distance=Distance.COSINE  # Косинусное расстояние для семантического сходства\n",
    "        )\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Коллекция可能 уже существует: {e}\")\n",
    "\n",
    "# Инициализация векторного хранилища LangChain для Qdrant\n",
    "vector_store = Qdrant(\n",
    "    client=client,\n",
    "    collection_name=\"fastapi_docs\",\n",
    "    embeddings=embedding_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcadf9b2-b771-4add-b862-9ea6c7e02dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример запроса\n",
    "query = \"How to create a POST endpoint in FastAPI?\"\n",
    "found_docs = vector_store.similarity_search(\n",
    "    query=query,\n",
    "    k=5  # Количество возвращаемых результатов\n",
    ")\n",
    "\n",
    "# Вывод результатов\n",
    "for i, doc in enumerate(found_docs):\n",
    "    print(f\"Результат #{i+1}:\")\n",
    "    print(f\"Контент: {doc.page_content[:200]}...\")\n",
    "    print(f\"Источник: {doc.metadata.get('source', 'N/A')}\")\n",
    "    print(f\"Рейтинг: {score}\")  # Если используется similarity_search_with_score\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eeaae7a6-fe3c-48bb-83ef-647225cb7e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.docstore.document import  Document\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "PATH = './docs/'\n",
    "\n",
    "def get_chunks(path) -> List[Tuple[str, str]]:\n",
    "    headers_to_split_on = [\n",
    "        ('#', 'Header 1'),\n",
    "        ('##', 'Header 2'),\n",
    "        ('###', 'Header 3'),\n",
    "        # ('###', 'Header 4')\n",
    "    ]\n",
    "\n",
    "    all_chunks = []\n",
    "    for root, _, files in os.walk(path):\n",
    "        for file in tqdm(files):\n",
    "            if file.endswith('.md'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    # Загрузка файла\n",
    "                    with open(file_path) as f:\n",
    "                        markdown_content = f.read()\n",
    "                        \n",
    "                    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on, strip_headers=False)\n",
    "                    doc_chunks = markdown_splitter.split_text(markdown_content)\n",
    "                    \n",
    "                    for chunk in doc_chunks:\n",
    "                        all_chunks.append((list(chunk.metadata.values())[0], chunk.page_content)) # на выходе список кортежей вида (заголовок, текст)\n",
    "                   \n",
    "                except Exception as e:\n",
    "                    print(f'Ошибка обработки файла {file_path}: {e}')\n",
    "                    continue\n",
    "\n",
    "    print(f'Всего создано {len(all_chunks)} чанков из {len(files)} файлов')\n",
    "    return all_chunks\n",
    "                \n",
    "\n",
    "# def chunk_cleaner(chunk):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a587d7d2-958e-4bce-91a3-3dc49ceb00ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 72.45it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 76.46it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 81.89it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 89.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:00<00:00, 124.11it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 100.88it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 99.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего создано 709 чанков из 5 файлов\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "c = get_chunks(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ed5ab87-314b-4290-befc-f4354ddc1faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Альтернативы, источники вдохновения и сравнения',\n",
       "  '# Альтернативы, источники вдохновения и сравнения  \\nЧто вдохновило на создание **FastAPI**, сравнение его с альтернативами и чему он научился у них.'),\n",
       " ('Альтернативы, источники вдохновения и сравнения',\n",
       "  '## Введение  \\n**FastAPI** не существовал бы, если б не было более ранних работ других людей.  \\nОни создали большое количество инструментов, которые вдохновили меня на создание **FastAPI**.  \\nЯ всячески избегал создания нового фреймворка в течение нескольких лет.\\nСначала я пытался собрать все нужные функции, которые ныне есть в **FastAPI**, используя множество различных фреймворков, плагинов и инструментов.  \\nНо в какой-то момент не осталось другого выбора, кроме как создать что-то, что предоставляло бы все эти функции сразу.\\nВзять самые лучшие идеи из предыдущих инструментов и, используя новые возможности Python (которых не было до версии 3.6, то есть подсказки типов), объединить их.'),\n",
       " ('Альтернативы, источники вдохновения и сравнения',\n",
       "  '## Предшествующие инструменты  \\n### <a href=\"https://www.djangoproject.com/\" class=\"external-link\" target=\"_blank\">Django</a>  \\nЭто самый популярный Python-фреймворк, и он пользуется доверием.\\nОн используется для создания проектов типа Instagram.  \\nDjango довольно тесно связан с реляционными базами данных (такими как MySQL или PostgreSQL), потому использовать NoSQL базы данных (например, Couchbase, MongoDB, Cassandra и т.п.) в качестве основного хранилища данных - непросто.  \\nОн был создан для генерации HTML-страниц на сервере, а не для создания API, используемых современными веб-интерфейсами (React, Vue.js, Angular и т.п.) или другими системами (например, <abbr title=\"Интернет вещей\">IoT</abbr>) взаимодействующими с сервером.')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12b0f333-9155-450d-a113-1ade152d47f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text: str) -> str:\n",
    "    '''Чистка текста от HTML-тегов, лишних символов и сусора с сохранением структуры и содержания'''\n",
    "\n",
    "    clean_text = text.strip() \n",
    "    # Удаляем теги HTML-теги\n",
    "    clean_text = re.sub(r'<a\\s+href=\"([^\"]*)\"[^>]*>([^<]*)</a>', r'\\2 (\\1)', clean_text)\n",
    "    clean_text = re.sub(r'///\\s*\\w+\\s*|.*?///', '', clean_text, re.DOTALL) # Символы типа '///'\n",
    "    clean_text = re.sub(r'#+\\s*', '', clean_text)  # Заголовки\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "466da910-1a89-494f-b01e-e5449ed87ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Django REST Framework (https://www.django-rest-framework.org/)  \\nФреймворк Django REST был создан, как гибкий инструментарий для создания веб-API на основе Django.  \\nDRF использовался многими компаниями, включая Mozilla, Red Hat и Eventbrite.  \\nЭто был один из первых примеров **автоматического документирования API** и это была одна из первых идей, вдохновивших на создание **FastAPI**.  \\n| Заметка  \\nDjango REST Framework был создан Tom Christie.\\nОн же создал Starlette и Uvicorn, на которых основан **FastAPI**.  \\n  \\n| Идея для **FastAPI**  \\nДолжно быть автоматическое создание документации API с пользовательским веб-интерфейсом.  \\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = '### <a href=\"https://www.django-rest-framework.org/\" class=\"external-link\" target=\"_blank\">Django REST Framework</a>  \\nФреймворк Django REST был создан, как гибкий инструментарий для создания веб-API на основе Django.  \\nDRF использовался многими компаниями, включая Mozilla, Red Hat и Eventbrite.  \\nЭто был один из первых примеров **автоматического документирования API** и это была одна из первых идей, вдохновивших на создание **FastAPI**.  \\n/// note | Заметка  \\nDjango REST Framework был создан Tom Christie.\\nОн же создал Starlette и Uvicorn, на которых основан **FastAPI**.  \\n///  \\n/// check | Идея для **FastAPI**  \\nДолжно быть автоматическое создание документации API с пользовательским веб-интерфейсом.  \\n///'\n",
    "clean_text(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6202e589-b38c-437a-8cca-22fe5e3c9519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from langchain.docstore.document import  Document\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "PATH = './docs/'\n",
    "\n",
    "def get_chunks(path) -> List[Tuple[str, str]]:\n",
    "    headers_to_split_on = [\n",
    "        ('#', 'Header 1'),\n",
    "        ('##', 'Header 2'),\n",
    "        ('###', 'Header 3'),\n",
    "    ]\n",
    "\n",
    "    all_chunks = []\n",
    "    for root, _, files in os.walk(path):\n",
    "        for file in tqdm(files):\n",
    "            if file.endswith('.md'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    # Загрузка файла\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        markdown_content = f.read()\n",
    "                        \n",
    "                    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on, strip_headers=False)\n",
    "                    doc_chunks = markdown_splitter.split_text(markdown_content)\n",
    "                    \n",
    "                    for chunk in doc_chunks:                        \n",
    "                        content = clean_text(chunk.page_content) # Чистим текст\n",
    "                        all_chunks.append((list(chunk.metadata.values())[0], content)) # на выходе список кортежей вида (заголовок, текст)\n",
    "                   \n",
    "                except Exception as e:\n",
    "                    print(f'Ошибка обработки файла {file_path}: {e}')\n",
    "                    continue\n",
    "\n",
    "    print(f'\\nВсего создано {len(all_chunks)} чанков из {len(files)} файлов')\n",
    "    return all_chunks\n",
    "                \n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    '''Чистка текста от HTML-тегов, лишних символов и сусора с сохранением структуры и содержания'''\n",
    "    \n",
    "    if not text or not text.strip():\n",
    "        return \"\"\n",
    "\n",
    "    cleaned = text.strip() \n",
    "\n",
    "    # Удаляем теги HTML-теги\n",
    "    cleaned = re.sub(r'<a\\s+href=\"([^\"]*)\"[^>]*>([^<]*)</a>', r'\\2 (\\1)', cleaned)\n",
    "    cleaned = re.sub(r'<[^>]+>', '', cleaned)\n",
    "\n",
    "    # Символы типа '///'\n",
    "    cleaned = re.sub(r'///.*?///', '', cleaned, flags=re.DOTALL)\n",
    "\n",
    "    # Заголовки\n",
    "    cleaned = re.sub(r'#+\\s*', '', cleaned)\n",
    "    \n",
    "    # Жирный текст\n",
    "    cleaned = re.sub(r'\\*\\*(.*?)\\*\\*', r'\\1', cleaned) \n",
    "    \n",
    "    # Курсив\n",
    "    cleaned = re.sub(r'\\*(.*?)\\*', r'\\1', cleaned)  \n",
    "    \n",
    "    # Удаляем лишние пробелы и переносы строк\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "\n",
    "    return cleaned\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d1173661-e176-457b-8137-ff6cadf7b180",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 167.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего создано 96 чанков из 6 файлов\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "c = get_chunks('./docs/deployment/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ec29d300-a3a6-4bb0-a45d-ea182ec91784",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c031a948-71fb-40fa-b585-4994212ae6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3d0500-5e79-4ccc-a2f3-8575046656c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929f1ff1-d061-4d9d-beab-23ff086bc85c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c152a35-43ae-446b-8bb9-6c078bbb9df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a8e69f0-5700-424c-99f9-d08ef8559c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = QdrantClient('http://localhost:6333')\n",
    "client.collection_exists(collection_name=\"{collection_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f41269b0-8cb1-41f6-a099-a675eac41407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ff\n"
     ]
    }
   ],
   "source": [
    "if not client.collection_exists(collection_name=\"{collection_name}\"):\n",
    "    print('ff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc96398-f84d-41bb-85b9-1b271b1953a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коллекция fastapi_docs уже существует\n",
      "Чанки загружены из файла chunks.pkl\n",
      "Для выхода введите \"выход\"\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client import models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "from md_parser import get_chunks\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "class VectorDB:\n",
    "    def __init__(self, collection_name: str = 'fastapi_docs'):\n",
    "        self.collection_name = collection_name\n",
    "        self.client = QdrantClient('http://localhost:6333') # Подключение к запущенному контейнеру\n",
    "        self.embedding_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "        # 'qilowoq/paraphrase-multilingual-mpnet-base-v2-en-ru'\n",
    "        # self.embedding_model = SentenceTransformer('distiluse-base-multilingual-cased-v2')\n",
    "\n",
    "        if self.client.collection_exists(collection_name):\n",
    "            print(f'Коллекция {collection_name} уже существует')\n",
    "        else:\n",
    "            self.client.create_collection(\n",
    "                collection_name=collection_name,\n",
    "                vectors_config= models.VectorParams(\n",
    "                    size=768, # Размерность модели\n",
    "                    distance=models.Distance.COSINE\n",
    "                )\n",
    "            )\n",
    "            print(f'Коллекция {self.collection_name} создана')\n",
    "        \n",
    "    def add_chunks(self, chunks: List[Tuple[str, str]]):\n",
    "        \n",
    "        if os.path.isfile('points.pkl'):\n",
    "            pass\n",
    "                \n",
    "        else:\n",
    "            print(f'Добавление точек в {self.collection_name}')\n",
    "            points = []\n",
    "            for idx, (header, content) in tqdm(enumerate(chunks)):\n",
    "                embedding = self.embedding_model.encode(content).tolist()\n",
    "                point = models.PointStruct(\n",
    "                    id=idx,\n",
    "                    vector=embedding,\n",
    "                    payload={\n",
    "                        'content': content,\n",
    "                        'header': header,\n",
    "                        'source': self.collection_name,\n",
    "                        'text_lenght': len(content)\n",
    "                    }\n",
    "                )\n",
    "                points.append(point)\n",
    "            with open('points.pkl', 'wb') as f:\n",
    "                pickle.dump(points, f)\n",
    "\n",
    "            self.client.upsert(\n",
    "                collection_name=self.collection_name,\n",
    "                points=points\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "    def search(self, query:str, limit=5):\n",
    "        '''Поиск похожих чанков'''\n",
    "        query_embedding = self.embedding_model.encode(query).tolist()\n",
    "\n",
    "        results = self.client.query_points(\n",
    "            collection_name=self.collection_name,\n",
    "            query=query_embedding,\n",
    "            limit=limit,\n",
    "            with_vectors=False\n",
    "        )\n",
    "\n",
    "        return results\n",
    "            \n",
    "            \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    client = VectorDB()\n",
    "\n",
    "    if os.path.isfile('chunks.pkl'):\n",
    "        with open('chunks.pkl', 'rb') as f:\n",
    "            chunks = pickle.load(f)\n",
    "            print(f'Чанки загружены из файла {f.name}')\n",
    "    else:\n",
    "        chunks = get_chunks()\n",
    "    client.add_chunks(chunks)\n",
    "    while True:\n",
    "        print(f'Для выхода введите \"выход\"')\n",
    "        query = str(input('Введите вопрос: ')).lower().strip()\n",
    "        if query =='выход':\n",
    "            break\n",
    "        limit = int(input('Введите лимит: '))\n",
    "        if not query:\n",
    "            print(f'Введите вопрос')\n",
    "            continue\n",
    "\n",
    "        result = client.search(query, limit)\n",
    "\n",
    "\n",
    "    for result in result.points:\n",
    "        print(f\"Score: {result.score:.3f}\")\n",
    "        print(f\"Header: {result.payload['header']}\")\n",
    "        print(f\"Content: {result.payload['content'][:200]}...\")\n",
    "        print(\"---\")\n",
    "\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384234fb-d02b-41a5-87ab-2d6ee7b3da05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4c9e1b-b1bd-4e0e-bb1d-bd5ebd8ba33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d543f0c2-397e-423c-964b-2a2fee9efc74",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=230 version=3 score=0.5712925 payload={'content': 'Создать Docker-образ Теперь, когда все файлы на своих местах, давайте создадим образ контейнера. * Перейдите в директорию проекта (в ту, где расположены `Dockerfile` и папка `app` с приложением). * Создай образ приложения FastAPI: ```console $ docker build -t myimage . ---> 100% ```', 'header': 'FastAPI и Docker-контейнеры', 'source': 'fastapi_docs', 'text_lenght': 283} vector=None shard_key=None order_value=None\n",
      "Score: 0.571\n",
      "Header: FastAPI и Docker-контейнеры\n",
      "Content: Создать Docker-образ Теперь, когда все файлы на своих местах, давайте создадим образ контейнера. * Перейдите в директорию проекта (в ту, где расположены `Dockerfile` и папка `app` с приложением). * Со...\n",
      "---\n",
      "id=224 version=3 score=0.53488636 payload={'content': 'Образы контейнеров Docker является одним из основных инструментов для создания образов и контейнеров и управления ими. Существует общедоступный Docker Hub (https://hub.docker.com/) с подготовленными официальными образами многих инструментов, окружений, баз данных и приложений. К примеру, есть официальный образ Python (https://hub.docker.com/_/python). Также там представлены и другие полезные образы, такие как базы данных: * PostgreSQL (https://hub.docker.com/_/postgres) * MySQL (https://hub.docker.com/_/mysql) * MongoDB (https://hub.docker.com/_/mongo) * Redis (https://hub.docker.com/_/redis) и т.п. Использование подготовленных образов значительно упрощает комбинирование и использование разных инструментов. Например, вы можете попытаться использовать новую базу данных. В большинстве случаев можно использовать официальный образ и всего лишь указать переменные окружения. Таким образом, вы можете изучить, что такое контейнеризация и Docker, и использовать полученные знания с разными инструментами и компонентами. Так, вы можете запустить одновременно множество контейнеров с базой данных, Python-приложением, веб-сервером, React-приложением и соединить их вместе через внутреннюю сеть. Все системы управления контейнерами (такие, как Docker или Kubernetes) имеют встроенные возможности для организации такого сетевого взаимодействия.', 'header': 'FastAPI и Docker-контейнеры', 'source': 'fastapi_docs', 'text_lenght': 1345} vector=None shard_key=None order_value=None\n",
      "Score: 0.535\n",
      "Header: FastAPI и Docker-контейнеры\n",
      "Content: Образы контейнеров Docker является одним из основных инструментов для создания образов и контейнеров и управления ими. Существует общедоступный Docker Hub (https://hub.docker.com/) с подготовленными о...\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for result in a.points[2:4]:\n",
    "    print(result)\n",
    "    print(f\"Score: {result.score:.3f}\")\n",
    "    print(f\"Header: {result.payload['header']}\")\n",
    "    print(f\"Content: {result.payload['content'][:200]}...\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb851245-cc48-4e90-9b66-56caf52047cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gigachat import GigaChat\n",
    "from vector_db import VectorDB\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "from dotenv import load_dotenv\n",
    "API_KEY = os.getenv('GIGACHAT_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c955a78-bb83-42b8-bc72-2f3596209ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGSystem:\n",
    "    def __init__(self):\n",
    "        self.vector_db = VectorDB()\n",
    "        self.giga_client = GigaChat(\n",
    "            credentials=API_KEY,\n",
    "            verify_ssl_certs=False\n",
    "        )\n",
    "    def ask(self, question: str):\n",
    "        # 1. Ищем релевантные чанки\n",
    "        results = self.vector_db.search(question, limit=6)\n",
    "        # 2. Формируем контекст\n",
    "        context = '\\n\\n'.join([\n",
    "            f'ИСточник: {r.payload['header']}\\n{r.payload['content']}'\n",
    "            for r in results.points\n",
    "        ])\n",
    "        # 3. Промт для GigaChat\n",
    "        prompt = f\"\"\"\n",
    "        Ответь на вопрос пользователя, основываясь на  предоставленный контекст.\n",
    "        Если ответа нет в контексте, ответь своими словами или скажи \"Не могу найти информацию в документации\".\n",
    "\n",
    "        Контекст:\n",
    "        {context}\n",
    "\n",
    "        Вопрос: {question}\n",
    "        Ответ:\n",
    "        \"\"\"\n",
    "        # 4. Ответ GigaChat\n",
    "        response = self.giga_client.chat(prompt)\n",
    "        return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70ad0a83-643e-497d-925e-e69177fc05f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коллекция fastapi_docs уже существует\n",
      "Не могу найти информацию в документации конкретно про машинное обучение в указанном контексте.\n",
      "\n",
      "Однако расскажу кратко сам.\n",
      "\n",
      "**Машинное обучение (МО)** — область информатики и математики, направленная на создание алгоритмов, позволяющих компьютерам обучаться на примерах данных и самостоятельно улучшать свою работу без явной программы действий программиста. \n",
      "\n",
      "Наиболее распространены следующие подходы МО:\n",
      "- **Обучение с учителем**: алгоритм получает размеченные данные (где указаны правильные ответы), учится находить закономерности и предсказывать результаты новых примеров.\n",
      "- **Обучение без учителя**: алгоритм находит скрытые структуры и взаимосвязи в неразмеченных данных.\n",
      "- **Глубокое обучение (нейронные сети)**: использование многослойных искусственных нейронных сетей для решения сложных задач, включая распознавание изображений, речи, перевод текста и многое другое.\n",
      "\n",
      "FastAPI часто используется разработчиками машинного обучения для быстрой и удобной реализации REST API, обеспечивающих взаимодействие моделей машинного обучения с внешними приложениями через HTTP-запросы. Например, пользователи могут отправлять входные данные модели, получать прогнозы и анализировать результаты в удобном формате JSON.\n"
     ]
    }
   ],
   "source": [
    "# Использование\n",
    "rag = RAGSystem()\n",
    "answer = rag.ask(\"расскажи про машинное обучение\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7ebc25-41d8-4459-b367-a30e390f11d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc75c73-a943-4435-8f6c-3e5222ea9076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31e4788c-27c6-4544-b469-4d7334a3c004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8349/1504278901.py:5: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat_model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatOpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model_name': 'gpt-3.5-t...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Инициализация модели\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m chat_model = \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-3.5-turbo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Вызов модели с сообщением\u001b[39;00m\n\u001b[32m      8\u001b[39m messages = [HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mРасскажи анекдот про программистов\u001b[39m\u001b[33m\"\u001b[39m)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/envs/env_3.12.3/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:223\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    221\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    222\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/envs/env_3.12.3/lib/python3.12/site-packages/langchain_core/load/serializable.py:130\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/envs/env_3.12.3/lib/python3.12/site-packages/pydantic/main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for ChatOpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model_name': 'gpt-3.5-t...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# Инициализация модели\n",
    "chat_model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "# Вызов модели с сообщением\n",
    "messages = [HumanMessage(content=\"Расскажи анекдот про программистов\")]\n",
    "response = chat_model.predict_messages(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50dfaba-a8b5-4f88-a100-578c2b2324c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
